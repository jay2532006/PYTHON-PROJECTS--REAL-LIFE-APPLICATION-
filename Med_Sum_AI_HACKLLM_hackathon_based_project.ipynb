{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jay2532006/PYTHON-PROJECTS--REAL-LIFE-APPLICATION-/blob/main/Med_Sum_AI_HACKLLM_hackathon_based_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OWSbhXP82-ez",
        "outputId": "3bf67f7c-b7a0-4e2d-eb3a-951677edff2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 91.2/91.2 kB 3.0 MB/s eta 0:00:00\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 40.1/40.1 kB 2.3 MB/s eta 0:00:00\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 10.0/10.0 MB 76.3 MB/s eta 0:00:00\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 12.0/12.0 MB 96.3 MB/s eta 0:00:00\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 11.6/11.6 MB 87.9 MB/s eta 0:00:00\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6.9/6.9 MB 98.0 MB/s eta 0:00:00\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.3/3.3 MB 69.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.2 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "pip install -U streamlit pandas torch transformers accelerate -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install py-localtunnel"
      ],
      "metadata": {
        "id": "QxZIj6dYoymt",
        "outputId": "e65e3b29-41e3-4a50-a4a0-f6614d6215c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting py-localtunnel\n",
            "  Downloading py_localtunnel-1.0.3-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.12/dist-packages (from py-localtunnel) (2.5.0)\n",
            "Downloading py_localtunnel-1.0.3-py3-none-any.whl (6.4 kB)\n",
            "Installing collected packages: py-localtunnel\n",
            "Successfully installed py-localtunnel-1.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train.py\n",
        "\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        ")\n",
        "from datasets import Dataset\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# --- Configuration ---\n",
        "BASE_MODEL = \"facebook/bart-large-cnn\"\n",
        "OUTPUT_DIR = \"./models/medsum-bart-finetuned\"\n",
        "TRAIN_FILE = \"train.json\"\n",
        "VALID_FILE = \"valid.json\"\n",
        "\n",
        "# Training hyperparameters\n",
        "NUM_TRAIN_EPOCHS = 3\n",
        "PER_DEVICE_TRAIN_BATCH_SIZE = 4\n",
        "PER_DEVICE_EVAL_BATCH_SIZE = 4\n",
        "WARMUP_STEPS = 500\n",
        "WEIGHT_DECAY = 0.01\n",
        "LOGGING_STEPS = 100\n",
        "EVALUATION_STRATEGY = \"epoch\"\n",
        "SAVE_STRATEGY = \"epoch\"\n",
        "LEARNING_RATE = 2e-5\n",
        "MAX_INPUT_LENGTH = 1024\n",
        "MAX_TARGET_LENGTH = 256\n",
        "\n",
        "def load_data_from_json(file_path: str) -> Dataset:\n",
        "    \"\"\"Loads data from a JSON file and converts it to a Hugging Face Dataset.\"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        # We need to structure the data into a format that the model can use.\n",
        "        # We'll create a prompt from the question and answers, and the summary is our target.\n",
        "        processed_records = []\n",
        "        for record in data:\n",
        "            question = record.get(\"question\", \"\")\n",
        "            # Combine all answers into a single text block\n",
        "            answers = \" \".join([ans if isinstance(ans, str) else ans.get('txt', '') for ans in record.get(\"answers\", [])])\n",
        "\n",
        "            # The input to the model will be the question and the answers\n",
        "            input_text = f\"Question: {question} Answers: {answers}\"\n",
        "\n",
        "            # The target is the summary. We'll use the first summary found.\n",
        "            summary = \"\"\n",
        "            if \"labelled_summaries\" in record and record[\"labelled_summaries\"]:\n",
        "                summary = next(iter(record[\"labelled_summaries\"].values()), \"\")\n",
        "\n",
        "            if input_text and summary:\n",
        "                processed_records.append({\"input_text\": input_text, \"target_text\": summary})\n",
        "\n",
        "        df = pd.DataFrame(processed_records)\n",
        "        return Dataset.from_pandas(df)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading or processing data from {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def preprocess_function(examples, tokenizer):\n",
        "    \"\"\"Tokenizes the input and target texts.\"\"\"\n",
        "    inputs = examples[\"input_text\"]\n",
        "    targets = examples[\"target_text\"]\n",
        "\n",
        "    model_inputs = tokenizer(inputs, max_length=MAX_INPUT_LENGTH, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # Setup the tokenizer for targets\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=MAX_TARGET_LENGTH, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run the fine-tuning process.\"\"\"\n",
        "    logger.info(\"Starting fine-tuning process...\")\n",
        "\n",
        "    # --- 1. Load Model and Tokenizer ---\n",
        "    logger.info(f\"Loading base model and tokenizer: {BASE_MODEL}\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(BASE_MODEL)\n",
        "\n",
        "    # --- 2. Load and Preprocess Data ---\n",
        "    logger.info(\"Loading and preprocessing datasets...\")\n",
        "    train_dataset = load_data_from_json(TRAIN_FILE)\n",
        "    valid_dataset = load_data_from_json(VALID_FILE)\n",
        "\n",
        "    if train_dataset is None or valid_dataset is None:\n",
        "        logger.error(\"Could not load datasets. Aborting training.\")\n",
        "        return\n",
        "\n",
        "    tokenized_train_dataset = train_dataset.map(lambda x: preprocess_function(x, tokenizer), batched=True)\n",
        "    tokenized_valid_dataset = valid_dataset.map(lambda x: preprocess_function(x, tokenizer), batched=True)\n",
        "\n",
        "    # --- 3. Define Training Arguments ---\n",
        "    logger.info(\"Defining training arguments...\")\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        num_train_epochs=NUM_TRAIN_EPOCHS,\n",
        "        per_device_train_batch_size=PER_DEVICE_TRAIN_BATCH_SIZE,\n",
        "        per_device_eval_batch_size=PER_DEVICE_EVAL_BATCH_SIZE,\n",
        "        warmup_steps=WARMUP_STEPS,\n",
        "        weight_decay=WEIGHT_DECAY,\n",
        "        logging_dir='./logs',\n",
        "        logging_steps=LOGGING_STEPS,\n",
        "        eval_strategy=EVALUATION_STRATEGY,\n",
        "        save_strategy=SAVE_STRATEGY,\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        load_best_model_at_end=True,\n",
        "        fp16=torch.cuda.is_available(), # Enable mixed precision training if CUDA is available\n",
        "        report_to=\"tensorboard\",\n",
        "    )\n",
        "\n",
        "    # --- 4. Create Trainer ---\n",
        "    data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_train_dataset,\n",
        "        eval_dataset=tokenized_valid_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "    )\n",
        "\n",
        "    # --- 5. Start Training ---\n",
        "    logger.info(\"ğŸš€ Starting model fine-tuning!\")\n",
        "    trainer.train()\n",
        "    logger.info(\"âœ… Fine-tuning complete.\")\n",
        "\n",
        "    # --- 6. Save the Model ---\n",
        "    logger.info(f\"Saving fine-tuned model to {OUTPUT_DIR}\")\n",
        "    trainer.save_model(OUTPUT_DIR)\n",
        "    tokenizer.save_pretrained(OUTPUT_DIR)\n",
        "    logger.info(\"âœ¨ Model saved successfully! You can now use it for inference.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure the output directory exists\n",
        "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfdX_uYE3Kv8",
        "outputId": "beed1a54-a6a6-4e49-c8f6-fd7604b2538b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw5kJ7PhB7E1",
        "outputId": "b3d3f06c-fbef-40ac-ec6b-85232d11399c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-30 06:27:00.037978: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756535220.058209    1447 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756535220.064225    1447 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756535220.080346    1447 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756535220.080374    1447 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756535220.080379    1447 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756535220.080384    1447 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-08-30 06:27:00.084992: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "config.json: 1.58kB [00:00, 8.68MB/s]\n",
            "vocab.json: 899kB [00:00, 24.5MB/s]\n",
            "merges.txt: 456kB [00:00, 69.2MB/s]\n",
            "tokenizer.json: 1.36MB [00:00, 108MB/s]\n",
            "model.safetensors: 100% 1.63G/1.63G [00:31<00:00, 51.0MB/s]\n",
            "generation_config.json: 100% 363/363 [00:00<00:00, 3.37MB/s]\n",
            "Map:   0% 0/2235 [00:00<?, ? examples/s]/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4007: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Map: 100% 2235/2235 [00:02<00:00, 899.45 examples/s]\n",
            "Map: 100% 959/959 [00:01<00:00, 935.43 examples/s]\n",
            "/content/train.py:128: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "{'loss': 6.2267, 'grad_norm': 31.117780685424805, 'learning_rate': 3.96e-06, 'epoch': 0.18}\n",
            "{'loss': 1.1126, 'grad_norm': 5.791814804077148, 'learning_rate': 7.960000000000002e-06, 'epoch': 0.36}\n",
            "{'loss': 0.6367, 'grad_norm': 2.86116886138916, 'learning_rate': 1.196e-05, 'epoch': 0.54}\n",
            "{'loss': 0.519, 'grad_norm': 1.7087721824645996, 'learning_rate': 1.5960000000000003e-05, 'epoch': 0.72}\n",
            "{'loss': 0.5146, 'grad_norm': 1.9679515361785889, 'learning_rate': 1.9960000000000002e-05, 'epoch': 0.89}\n",
            " 33% 559/1677 [05:20<10:51,  1.71it/s]\n",
            "  0% 0/240 [00:00<?, ?it/s]\u001b[A\n",
            "  1% 2/240 [00:00<00:18, 12.85it/s]\u001b[A\n",
            "  2% 4/240 [00:00<00:31,  7.58it/s]\u001b[A\n",
            "  2% 5/240 [00:00<00:32,  7.30it/s]\u001b[A\n",
            "  2% 6/240 [00:00<00:34,  6.85it/s]\u001b[A\n",
            "  3% 7/240 [00:00<00:34,  6.78it/s]\u001b[A\n",
            "  3% 8/240 [00:01<00:35,  6.57it/s]\u001b[A\n",
            "  4% 9/240 [00:01<00:35,  6.42it/s]\u001b[A\n",
            "  4% 10/240 [00:01<00:34,  6.59it/s]\u001b[A\n",
            "  5% 11/240 [00:01<00:35,  6.54it/s]\u001b[A\n",
            "  5% 12/240 [00:01<00:35,  6.51it/s]\u001b[A\n",
            "  5% 13/240 [00:01<00:34,  6.53it/s]\u001b[A\n",
            "  6% 14/240 [00:02<00:34,  6.49it/s]\u001b[A\n",
            "  6% 15/240 [00:02<00:34,  6.48it/s]\u001b[A\n",
            "  7% 16/240 [00:02<00:34,  6.49it/s]\u001b[A\n",
            "  7% 17/240 [00:02<00:34,  6.49it/s]\u001b[A\n",
            "  8% 18/240 [00:02<00:34,  6.46it/s]\u001b[A\n",
            "  8% 19/240 [00:02<00:34,  6.49it/s]\u001b[A\n",
            "  8% 20/240 [00:02<00:33,  6.48it/s]\u001b[A\n",
            "  9% 21/240 [00:03<00:33,  6.46it/s]\u001b[A\n",
            "  9% 22/240 [00:03<00:33,  6.48it/s]\u001b[A\n",
            " 10% 23/240 [00:03<00:33,  6.47it/s]\u001b[A\n",
            " 10% 24/240 [00:03<00:33,  6.47it/s]\u001b[A\n",
            " 10% 25/240 [00:03<00:33,  6.40it/s]\u001b[A\n",
            " 11% 26/240 [00:03<00:33,  6.47it/s]\u001b[A\n",
            " 11% 27/240 [00:04<00:33,  6.42it/s]\u001b[A\n",
            " 12% 28/240 [00:04<00:32,  6.45it/s]\u001b[A\n",
            " 12% 29/240 [00:04<00:32,  6.41it/s]\u001b[A\n",
            " 12% 30/240 [00:04<00:32,  6.47it/s]\u001b[A\n",
            " 13% 31/240 [00:04<00:32,  6.46it/s]\u001b[A\n",
            " 13% 32/240 [00:04<00:32,  6.45it/s]\u001b[A\n",
            " 14% 33/240 [00:04<00:32,  6.45it/s]\u001b[A\n",
            " 14% 34/240 [00:05<00:31,  6.47it/s]\u001b[A\n",
            " 15% 35/240 [00:05<00:31,  6.44it/s]\u001b[A\n",
            " 15% 36/240 [00:05<00:31,  6.44it/s]\u001b[A\n",
            " 15% 37/240 [00:05<00:31,  6.42it/s]\u001b[A\n",
            " 16% 38/240 [00:05<00:31,  6.40it/s]\u001b[A\n",
            " 16% 39/240 [00:05<00:31,  6.46it/s]\u001b[A\n",
            " 17% 40/240 [00:06<00:30,  6.46it/s]\u001b[A\n",
            " 17% 41/240 [00:06<00:30,  6.42it/s]\u001b[A\n",
            " 18% 42/240 [00:06<00:30,  6.41it/s]\u001b[A\n",
            " 18% 43/240 [00:06<00:30,  6.46it/s]\u001b[A\n",
            " 18% 44/240 [00:06<00:30,  6.45it/s]\u001b[A\n",
            " 19% 45/240 [00:06<00:30,  6.46it/s]\u001b[A\n",
            " 19% 46/240 [00:07<00:29,  6.48it/s]\u001b[A\n",
            " 20% 47/240 [00:07<00:29,  6.45it/s]\u001b[A\n",
            " 20% 48/240 [00:07<00:29,  6.46it/s]\u001b[A\n",
            " 20% 49/240 [00:07<00:29,  6.43it/s]\u001b[A\n",
            " 21% 50/240 [00:07<00:29,  6.43it/s]\u001b[A\n",
            " 21% 51/240 [00:07<00:29,  6.39it/s]\u001b[A\n",
            " 22% 52/240 [00:07<00:29,  6.41it/s]\u001b[A\n",
            " 22% 53/240 [00:08<00:29,  6.43it/s]\u001b[A\n",
            " 22% 54/240 [00:08<00:29,  6.34it/s]\u001b[A\n",
            " 23% 55/240 [00:08<00:28,  6.42it/s]\u001b[A\n",
            " 23% 56/240 [00:08<00:28,  6.41it/s]\u001b[A\n",
            " 24% 57/240 [00:08<00:29,  6.30it/s]\u001b[A\n",
            " 24% 58/240 [00:08<00:28,  6.45it/s]\u001b[A\n",
            " 25% 59/240 [00:09<00:27,  6.50it/s]\u001b[A\n",
            " 25% 60/240 [00:09<00:27,  6.44it/s]\u001b[A\n",
            " 25% 61/240 [00:09<00:27,  6.47it/s]\u001b[A\n",
            " 26% 62/240 [00:09<00:27,  6.42it/s]\u001b[A\n",
            " 26% 63/240 [00:09<00:27,  6.47it/s]\u001b[A\n",
            " 27% 64/240 [00:09<00:27,  6.47it/s]\u001b[A\n",
            " 27% 65/240 [00:09<00:27,  6.45it/s]\u001b[A\n",
            " 28% 66/240 [00:10<00:27,  6.44it/s]\u001b[A\n",
            " 28% 67/240 [00:10<00:26,  6.44it/s]\u001b[A\n",
            " 28% 68/240 [00:10<00:26,  6.46it/s]\u001b[A\n",
            " 29% 69/240 [00:10<00:26,  6.44it/s]\u001b[A\n",
            " 29% 70/240 [00:10<00:26,  6.45it/s]\u001b[A\n",
            " 30% 71/240 [00:10<00:26,  6.45it/s]\u001b[A\n",
            " 30% 72/240 [00:11<00:26,  6.44it/s]\u001b[A\n",
            " 30% 73/240 [00:11<00:25,  6.45it/s]\u001b[A\n",
            " 31% 74/240 [00:11<00:26,  6.31it/s]\u001b[A\n",
            " 31% 75/240 [00:11<00:25,  6.37it/s]\u001b[A\n",
            " 32% 76/240 [00:11<00:25,  6.34it/s]\u001b[A\n",
            " 32% 77/240 [00:11<00:25,  6.27it/s]\u001b[A\n",
            " 32% 78/240 [00:12<00:25,  6.33it/s]\u001b[A\n",
            " 33% 79/240 [00:12<00:25,  6.34it/s]\u001b[A\n",
            " 33% 80/240 [00:12<00:25,  6.36it/s]\u001b[A\n",
            " 34% 81/240 [00:12<00:25,  6.34it/s]\u001b[A\n",
            " 34% 82/240 [00:12<00:24,  6.33it/s]\u001b[A\n",
            " 35% 83/240 [00:12<00:24,  6.30it/s]\u001b[A\n",
            " 35% 84/240 [00:12<00:24,  6.31it/s]\u001b[A\n",
            " 35% 85/240 [00:13<00:24,  6.30it/s]\u001b[A\n",
            " 36% 86/240 [00:13<00:24,  6.21it/s]\u001b[A\n",
            " 36% 87/240 [00:13<00:24,  6.26it/s]\u001b[A\n",
            " 37% 88/240 [00:13<00:23,  6.39it/s]\u001b[A\n",
            " 37% 89/240 [00:13<00:23,  6.45it/s]\u001b[A\n",
            " 38% 90/240 [00:13<00:23,  6.46it/s]\u001b[A\n",
            " 38% 91/240 [00:14<00:23,  6.36it/s]\u001b[A\n",
            " 38% 92/240 [00:14<00:22,  6.44it/s]\u001b[A\n",
            " 39% 93/240 [00:14<00:22,  6.45it/s]\u001b[A\n",
            " 39% 94/240 [00:14<00:22,  6.43it/s]\u001b[A\n",
            " 40% 95/240 [00:14<00:22,  6.48it/s]\u001b[A\n",
            " 40% 96/240 [00:14<00:22,  6.43it/s]\u001b[A\n",
            " 40% 97/240 [00:14<00:22,  6.30it/s]\u001b[A\n",
            " 41% 98/240 [00:15<00:21,  6.46it/s]\u001b[A\n",
            " 41% 99/240 [00:15<00:21,  6.45it/s]\u001b[A\n",
            " 42% 100/240 [00:15<00:21,  6.46it/s]\u001b[A\n",
            " 42% 101/240 [00:15<00:21,  6.46it/s]\u001b[A\n",
            " 42% 102/240 [00:15<00:21,  6.47it/s]\u001b[A\n",
            " 43% 103/240 [00:15<00:21,  6.44it/s]\u001b[A\n",
            " 43% 104/240 [00:16<00:21,  6.44it/s]\u001b[A\n",
            " 44% 105/240 [00:16<00:20,  6.45it/s]\u001b[A\n",
            " 44% 106/240 [00:16<00:20,  6.44it/s]\u001b[A\n",
            " 45% 107/240 [00:16<00:20,  6.44it/s]\u001b[A\n",
            " 45% 108/240 [00:16<00:20,  6.46it/s]\u001b[A\n",
            " 45% 109/240 [00:16<00:20,  6.44it/s]\u001b[A\n",
            " 46% 110/240 [00:17<00:20,  6.43it/s]\u001b[A\n",
            " 46% 111/240 [00:17<00:20,  6.40it/s]\u001b[A\n",
            " 47% 112/240 [00:17<00:19,  6.41it/s]\u001b[A\n",
            " 47% 113/240 [00:17<00:19,  6.42it/s]\u001b[A\n",
            " 48% 114/240 [00:17<00:19,  6.42it/s]\u001b[A\n",
            " 48% 115/240 [00:17<00:19,  6.45it/s]\u001b[A\n",
            " 48% 116/240 [00:17<00:19,  6.46it/s]\u001b[A\n",
            " 49% 117/240 [00:18<00:19,  6.39it/s]\u001b[A\n",
            " 49% 118/240 [00:18<00:18,  6.43it/s]\u001b[A\n",
            " 50% 119/240 [00:18<00:18,  6.44it/s]\u001b[A\n",
            " 50% 120/240 [00:18<00:18,  6.46it/s]\u001b[A\n",
            " 50% 121/240 [00:18<00:18,  6.45it/s]\u001b[A\n",
            " 51% 122/240 [00:18<00:18,  6.44it/s]\u001b[A\n",
            " 51% 123/240 [00:19<00:18,  6.46it/s]\u001b[A\n",
            " 52% 124/240 [00:19<00:17,  6.45it/s]\u001b[A\n",
            " 52% 125/240 [00:19<00:17,  6.42it/s]\u001b[A\n",
            " 52% 126/240 [00:19<00:17,  6.47it/s]\u001b[A\n",
            " 53% 127/240 [00:19<00:17,  6.45it/s]\u001b[A\n",
            " 53% 128/240 [00:19<00:17,  6.46it/s]\u001b[A\n",
            " 54% 129/240 [00:19<00:17,  6.45it/s]\u001b[A\n",
            " 54% 130/240 [00:20<00:17,  6.45it/s]\u001b[A\n",
            " 55% 131/240 [00:20<00:17,  6.40it/s]\u001b[A\n",
            " 55% 132/240 [00:20<00:16,  6.46it/s]\u001b[A\n",
            " 55% 133/240 [00:20<00:16,  6.45it/s]\u001b[A\n",
            " 56% 134/240 [00:20<00:16,  6.44it/s]\u001b[A\n",
            " 56% 135/240 [00:20<00:16,  6.43it/s]\u001b[A\n",
            " 57% 136/240 [00:21<00:16,  6.43it/s]\u001b[A\n",
            " 57% 137/240 [00:21<00:16,  6.42it/s]\u001b[A\n",
            " 57% 138/240 [00:21<00:15,  6.43it/s]\u001b[A\n",
            " 58% 139/240 [00:21<00:15,  6.42it/s]\u001b[A\n",
            " 58% 140/240 [00:21<00:15,  6.48it/s]\u001b[A\n",
            " 59% 141/240 [00:21<00:15,  6.47it/s]\u001b[A\n",
            " 59% 142/240 [00:21<00:15,  6.46it/s]\u001b[A\n",
            " 60% 143/240 [00:22<00:14,  6.47it/s]\u001b[A\n",
            " 60% 144/240 [00:22<00:14,  6.46it/s]\u001b[A\n",
            " 60% 145/240 [00:22<00:14,  6.45it/s]\u001b[A\n",
            " 61% 146/240 [00:22<00:14,  6.46it/s]\u001b[A\n",
            " 61% 147/240 [00:22<00:14,  6.46it/s]\u001b[A\n",
            " 62% 148/240 [00:22<00:14,  6.45it/s]\u001b[A\n",
            " 62% 149/240 [00:23<00:14,  6.46it/s]\u001b[A\n",
            " 62% 150/240 [00:23<00:13,  6.47it/s]\u001b[A\n",
            " 63% 151/240 [00:23<00:13,  6.44it/s]\u001b[A\n",
            " 63% 152/240 [00:23<00:13,  6.38it/s]\u001b[A\n",
            " 64% 153/240 [00:23<00:13,  6.38it/s]\u001b[A\n",
            " 64% 154/240 [00:23<00:13,  6.36it/s]\u001b[A\n",
            " 65% 155/240 [00:23<00:13,  6.33it/s]\u001b[A\n",
            " 65% 156/240 [00:24<00:13,  6.29it/s]\u001b[A\n",
            " 65% 157/240 [00:24<00:13,  6.30it/s]\u001b[A\n",
            " 66% 158/240 [00:24<00:12,  6.34it/s]\u001b[A\n",
            " 66% 159/240 [00:24<00:12,  6.31it/s]\u001b[A\n",
            " 67% 160/240 [00:24<00:12,  6.30it/s]\u001b[A\n",
            " 67% 161/240 [00:24<00:12,  6.23it/s]\u001b[A\n",
            " 68% 162/240 [00:25<00:12,  6.29it/s]\u001b[A\n",
            " 68% 163/240 [00:25<00:12,  6.25it/s]\u001b[A\n",
            " 68% 164/240 [00:25<00:12,  6.20it/s]\u001b[A\n",
            " 69% 165/240 [00:25<00:11,  6.27it/s]\u001b[A\n",
            " 69% 166/240 [00:25<00:11,  6.41it/s]\u001b[A\n",
            " 70% 167/240 [00:25<00:11,  6.40it/s]\u001b[A\n",
            " 70% 168/240 [00:26<00:11,  6.42it/s]\u001b[A\n",
            " 70% 169/240 [00:26<00:11,  6.44it/s]\u001b[A\n",
            " 71% 170/240 [00:26<00:11,  6.34it/s]\u001b[A\n",
            " 71% 171/240 [00:26<00:10,  6.47it/s]\u001b[A\n",
            " 72% 172/240 [00:26<00:10,  6.44it/s]\u001b[A\n",
            " 72% 173/240 [00:26<00:10,  6.45it/s]\u001b[A\n",
            " 72% 174/240 [00:26<00:10,  6.47it/s]\u001b[A\n",
            " 73% 175/240 [00:27<00:10,  6.48it/s]\u001b[A\n",
            " 73% 176/240 [00:27<00:09,  6.46it/s]\u001b[A\n",
            " 74% 177/240 [00:27<00:09,  6.47it/s]\u001b[A\n",
            " 74% 178/240 [00:27<00:09,  6.40it/s]\u001b[A\n",
            " 75% 179/240 [00:27<00:09,  6.47it/s]\u001b[A\n",
            " 75% 180/240 [00:27<00:09,  6.48it/s]\u001b[A\n",
            " 75% 181/240 [00:28<00:09,  6.45it/s]\u001b[A\n",
            " 76% 182/240 [00:28<00:09,  6.44it/s]\u001b[A\n",
            " 76% 183/240 [00:28<00:08,  6.46it/s]\u001b[A\n",
            " 77% 184/240 [00:28<00:08,  6.41it/s]\u001b[A\n",
            " 77% 185/240 [00:28<00:08,  6.39it/s]\u001b[A\n",
            " 78% 186/240 [00:28<00:08,  6.44it/s]\u001b[A\n",
            " 78% 187/240 [00:29<00:08,  6.40it/s]\u001b[A\n",
            " 78% 188/240 [00:29<00:08,  6.45it/s]\u001b[A\n",
            " 79% 189/240 [00:29<00:07,  6.46it/s]\u001b[A\n",
            " 79% 190/240 [00:29<00:07,  6.29it/s]\u001b[A\n",
            " 80% 191/240 [00:29<00:07,  6.47it/s]\u001b[A\n",
            " 80% 192/240 [00:29<00:07,  6.50it/s]\u001b[A\n",
            " 80% 193/240 [00:29<00:07,  6.47it/s]\u001b[A\n",
            " 81% 194/240 [00:30<00:07,  6.46it/s]\u001b[A\n",
            " 81% 195/240 [00:30<00:06,  6.46it/s]\u001b[A\n",
            " 82% 196/240 [00:30<00:06,  6.44it/s]\u001b[A\n",
            " 82% 197/240 [00:30<00:06,  6.46it/s]\u001b[A\n",
            " 82% 198/240 [00:30<00:06,  6.43it/s]\u001b[A\n",
            " 83% 199/240 [00:30<00:06,  6.44it/s]\u001b[A\n",
            " 83% 200/240 [00:31<00:06,  6.38it/s]\u001b[A\n",
            " 84% 201/240 [00:31<00:06,  6.42it/s]\u001b[A\n",
            " 84% 202/240 [00:31<00:05,  6.43it/s]\u001b[A\n",
            " 85% 203/240 [00:31<00:05,  6.43it/s]\u001b[A\n",
            " 85% 204/240 [00:31<00:05,  6.42it/s]\u001b[A\n",
            " 85% 205/240 [00:31<00:05,  6.42it/s]\u001b[A\n",
            " 86% 206/240 [00:31<00:05,  6.42it/s]\u001b[A\n",
            " 86% 207/240 [00:32<00:05,  6.44it/s]\u001b[A\n",
            " 87% 208/240 [00:32<00:04,  6.43it/s]\u001b[A\n",
            " 87% 209/240 [00:32<00:04,  6.43it/s]\u001b[A\n",
            " 88% 210/240 [00:32<00:04,  6.38it/s]\u001b[A\n",
            " 88% 211/240 [00:32<00:04,  6.47it/s]\u001b[A\n",
            " 88% 212/240 [00:32<00:04,  6.47it/s]\u001b[A\n",
            " 89% 213/240 [00:33<00:04,  6.46it/s]\u001b[A\n",
            " 89% 214/240 [00:33<00:04,  6.45it/s]\u001b[A\n",
            " 90% 215/240 [00:33<00:03,  6.44it/s]\u001b[A\n",
            " 90% 216/240 [00:33<00:03,  6.47it/s]\u001b[A\n",
            " 90% 217/240 [00:33<00:03,  6.45it/s]\u001b[A\n",
            " 91% 218/240 [00:33<00:03,  6.45it/s]\u001b[A\n",
            " 91% 219/240 [00:33<00:03,  6.46it/s]\u001b[A\n",
            " 92% 220/240 [00:34<00:03,  6.46it/s]\u001b[A\n",
            " 92% 221/240 [00:34<00:02,  6.45it/s]\u001b[A\n",
            " 92% 222/240 [00:34<00:02,  6.44it/s]\u001b[A\n",
            " 93% 223/240 [00:34<00:02,  6.43it/s]\u001b[A\n",
            " 93% 224/240 [00:34<00:02,  6.42it/s]\u001b[A\n",
            " 94% 225/240 [00:34<00:02,  6.45it/s]\u001b[A\n",
            " 94% 226/240 [00:35<00:02,  6.43it/s]\u001b[A\n",
            " 95% 227/240 [00:35<00:02,  6.42it/s]\u001b[A\n",
            " 95% 228/240 [00:35<00:01,  6.41it/s]\u001b[A\n",
            " 95% 229/240 [00:35<00:01,  6.44it/s]\u001b[A\n",
            " 96% 230/240 [00:35<00:01,  6.32it/s]\u001b[A\n",
            " 96% 231/240 [00:35<00:01,  6.37it/s]\u001b[A\n",
            " 97% 232/240 [00:36<00:01,  6.35it/s]\u001b[A\n",
            " 97% 233/240 [00:36<00:01,  6.33it/s]\u001b[A\n",
            " 98% 234/240 [00:36<00:00,  6.31it/s]\u001b[A\n",
            " 98% 235/240 [00:36<00:00,  6.25it/s]\u001b[A\n",
            " 98% 236/240 [00:36<00:00,  6.29it/s]\u001b[A\n",
            " 99% 237/240 [00:36<00:00,  6.31it/s]\u001b[A\n",
            " 99% 238/240 [00:36<00:00,  6.34it/s]\u001b[A\n",
            "100% 239/240 [00:37<00:00,  6.26it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.4935954511165619, 'eval_runtime': 37.4548, 'eval_samples_per_second': 25.604, 'eval_steps_per_second': 6.408, 'epoch': 1.0}\n",
            " 33% 559/1677 [05:57<10:51,  1.71it/s]\n",
            "100% 240/240 [00:37<00:00,  6.68it/s]\u001b[A\n",
            "                                     \u001b[A/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py:4034: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
            "  warnings.warn(\n",
            "{'loss': 0.4551, 'grad_norm': 1.9987480640411377, 'learning_rate': 1.8317757009345797e-05, 'epoch': 1.07}\n",
            "{'loss': 0.394, 'grad_norm': 1.4791465997695923, 'learning_rate': 1.6618521665250638e-05, 'epoch': 1.25}\n",
            "{'loss': 0.4412, 'grad_norm': 2.96168851852417, 'learning_rate': 1.4919286321155482e-05, 'epoch': 1.43}\n",
            "{'loss': 0.4063, 'grad_norm': 1.8282461166381836, 'learning_rate': 1.3220050977060323e-05, 'epoch': 1.61}\n",
            "{'loss': 0.3886, 'grad_norm': 1.506718397140503, 'learning_rate': 1.1520815632965168e-05, 'epoch': 1.79}\n",
            "{'loss': 0.4075, 'grad_norm': 2.166639804840088, 'learning_rate': 9.82158028887001e-06, 'epoch': 1.97}\n",
            " 67% 1118/1677 [12:29<04:59,  1.87it/s]\n",
            "  0% 0/240 [00:00<?, ?it/s]\u001b[A\n",
            "  1% 2/240 [00:00<00:18, 12.90it/s]\u001b[A\n",
            "  2% 4/240 [00:00<00:29,  7.93it/s]\u001b[A\n",
            "  2% 5/240 [00:00<00:31,  7.41it/s]\u001b[A\n",
            "  2% 6/240 [00:00<00:32,  7.12it/s]\u001b[A\n",
            "  3% 7/240 [00:00<00:33,  6.89it/s]\u001b[A\n",
            "  3% 8/240 [00:01<00:34,  6.76it/s]\u001b[A\n",
            "  4% 9/240 [00:01<00:34,  6.62it/s]\u001b[A\n",
            "  4% 10/240 [00:01<00:35,  6.54it/s]\u001b[A\n",
            "  5% 11/240 [00:01<00:34,  6.56it/s]\u001b[A\n",
            "  5% 12/240 [00:01<00:34,  6.53it/s]\u001b[A\n",
            "  5% 13/240 [00:01<00:34,  6.51it/s]\u001b[A\n",
            "  6% 14/240 [00:02<00:34,  6.50it/s]\u001b[A\n",
            "  6% 15/240 [00:02<00:34,  6.50it/s]\u001b[A\n",
            "  7% 16/240 [00:02<00:34,  6.48it/s]\u001b[A\n",
            "  7% 17/240 [00:02<00:34,  6.49it/s]\u001b[A\n",
            "  8% 18/240 [00:02<00:34,  6.49it/s]\u001b[A\n",
            "  8% 19/240 [00:02<00:34,  6.49it/s]\u001b[A\n",
            "  8% 20/240 [00:02<00:33,  6.49it/s]\u001b[A\n",
            "  9% 21/240 [00:03<00:33,  6.46it/s]\u001b[A\n",
            "  9% 22/240 [00:03<00:33,  6.45it/s]\u001b[A\n",
            " 10% 23/240 [00:03<00:33,  6.46it/s]\u001b[A\n",
            " 10% 24/240 [00:03<00:33,  6.44it/s]\u001b[A\n",
            " 10% 25/240 [00:03<00:33,  6.45it/s]\u001b[A\n",
            " 11% 26/240 [00:03<00:33,  6.44it/s]\u001b[A\n",
            " 11% 27/240 [00:04<00:33,  6.42it/s]\u001b[A\n",
            " 12% 28/240 [00:04<00:32,  6.44it/s]\u001b[A\n",
            " 12% 29/240 [00:04<00:32,  6.46it/s]\u001b[A\n",
            " 12% 30/240 [00:04<00:32,  6.44it/s]\u001b[A\n",
            " 13% 31/240 [00:04<00:32,  6.49it/s]\u001b[A\n",
            " 13% 32/240 [00:04<00:32,  6.46it/s]\u001b[A\n",
            " 14% 33/240 [00:04<00:31,  6.47it/s]\u001b[A\n",
            " 14% 34/240 [00:05<00:31,  6.46it/s]\u001b[A\n",
            " 15% 35/240 [00:05<00:31,  6.47it/s]\u001b[A\n",
            " 15% 36/240 [00:05<00:32,  6.34it/s]\u001b[A\n",
            " 15% 37/240 [00:05<00:31,  6.40it/s]\u001b[A\n",
            " 16% 38/240 [00:05<00:31,  6.40it/s]\u001b[A\n",
            " 16% 39/240 [00:05<00:31,  6.36it/s]\u001b[A\n",
            " 17% 40/240 [00:06<00:31,  6.30it/s]\u001b[A\n",
            " 17% 41/240 [00:06<00:31,  6.30it/s]\u001b[A\n",
            " 18% 42/240 [00:06<00:31,  6.36it/s]\u001b[A\n",
            " 18% 43/240 [00:06<00:31,  6.29it/s]\u001b[A\n",
            " 18% 44/240 [00:06<00:31,  6.31it/s]\u001b[A\n",
            " 19% 45/240 [00:06<00:31,  6.23it/s]\u001b[A\n",
            " 19% 46/240 [00:07<00:30,  6.27it/s]\u001b[A\n",
            " 20% 47/240 [00:07<00:31,  6.20it/s]\u001b[A\n",
            " 20% 48/240 [00:07<00:30,  6.21it/s]\u001b[A\n",
            " 20% 49/240 [00:07<00:30,  6.29it/s]\u001b[A\n",
            " 21% 50/240 [00:07<00:30,  6.32it/s]\u001b[A\n",
            " 21% 51/240 [00:07<00:29,  6.46it/s]\u001b[A\n",
            " 22% 52/240 [00:07<00:29,  6.44it/s]\u001b[A\n",
            " 22% 53/240 [00:08<00:29,  6.42it/s]\u001b[A\n",
            " 22% 54/240 [00:08<00:28,  6.44it/s]\u001b[A\n",
            " 23% 55/240 [00:08<00:28,  6.48it/s]\u001b[A\n",
            " 23% 56/240 [00:08<00:28,  6.47it/s]\u001b[A\n",
            " 24% 57/240 [00:08<00:28,  6.46it/s]\u001b[A\n",
            " 24% 58/240 [00:08<00:28,  6.49it/s]\u001b[A\n",
            " 25% 59/240 [00:09<00:27,  6.47it/s]\u001b[A\n",
            " 25% 60/240 [00:09<00:27,  6.48it/s]\u001b[A\n",
            " 25% 61/240 [00:09<00:27,  6.48it/s]\u001b[A\n",
            " 26% 62/240 [00:09<00:27,  6.46it/s]\u001b[A\n",
            " 26% 63/240 [00:09<00:27,  6.45it/s]\u001b[A\n",
            " 27% 64/240 [00:09<00:27,  6.45it/s]\u001b[A\n",
            " 27% 65/240 [00:09<00:27,  6.45it/s]\u001b[A\n",
            " 28% 66/240 [00:10<00:27,  6.44it/s]\u001b[A\n",
            " 28% 67/240 [00:10<00:26,  6.45it/s]\u001b[A\n",
            " 28% 68/240 [00:10<00:26,  6.42it/s]\u001b[A\n",
            " 29% 69/240 [00:10<00:26,  6.43it/s]\u001b[A\n",
            " 29% 70/240 [00:10<00:26,  6.40it/s]\u001b[A\n",
            " 30% 71/240 [00:10<00:26,  6.46it/s]\u001b[A\n",
            " 30% 72/240 [00:11<00:26,  6.45it/s]\u001b[A\n",
            " 30% 73/240 [00:11<00:25,  6.46it/s]\u001b[A\n",
            " 31% 74/240 [00:11<00:25,  6.44it/s]\u001b[A\n",
            " 31% 75/240 [00:11<00:25,  6.46it/s]\u001b[A\n",
            " 32% 76/240 [00:11<00:25,  6.39it/s]\u001b[A\n",
            " 32% 77/240 [00:11<00:25,  6.46it/s]\u001b[A\n",
            " 32% 78/240 [00:11<00:25,  6.47it/s]\u001b[A\n",
            " 33% 79/240 [00:12<00:24,  6.46it/s]\u001b[A\n",
            " 33% 80/240 [00:12<00:24,  6.42it/s]\u001b[A\n",
            " 34% 81/240 [00:12<00:24,  6.51it/s]\u001b[A\n",
            " 34% 82/240 [00:12<00:24,  6.48it/s]\u001b[A\n",
            " 35% 83/240 [00:12<00:24,  6.49it/s]\u001b[A\n",
            " 35% 84/240 [00:12<00:24,  6.48it/s]\u001b[A\n",
            " 35% 85/240 [00:13<00:23,  6.47it/s]\u001b[A\n",
            " 36% 86/240 [00:13<00:23,  6.47it/s]\u001b[A\n",
            " 36% 87/240 [00:13<00:23,  6.49it/s]\u001b[A\n",
            " 37% 88/240 [00:13<00:23,  6.49it/s]\u001b[A\n",
            " 37% 89/240 [00:13<00:23,  6.50it/s]\u001b[A\n",
            " 38% 90/240 [00:13<00:23,  6.44it/s]\u001b[A\n",
            " 38% 91/240 [00:14<00:22,  6.48it/s]\u001b[A\n",
            " 38% 92/240 [00:14<00:22,  6.49it/s]\u001b[A\n",
            " 39% 93/240 [00:14<00:22,  6.46it/s]\u001b[A\n",
            " 39% 94/240 [00:14<00:22,  6.45it/s]\u001b[A\n",
            " 40% 95/240 [00:14<00:22,  6.45it/s]\u001b[A\n",
            " 40% 96/240 [00:14<00:22,  6.43it/s]\u001b[A\n",
            " 40% 97/240 [00:14<00:22,  6.43it/s]\u001b[A\n",
            " 41% 98/240 [00:15<00:22,  6.45it/s]\u001b[A\n",
            " 41% 99/240 [00:15<00:21,  6.42it/s]\u001b[A\n",
            " 42% 100/240 [00:15<00:21,  6.47it/s]\u001b[A\n",
            " 42% 101/240 [00:15<00:21,  6.44it/s]\u001b[A\n",
            " 42% 102/240 [00:15<00:21,  6.46it/s]\u001b[A\n",
            " 43% 103/240 [00:15<00:21,  6.46it/s]\u001b[A\n",
            " 43% 104/240 [00:16<00:21,  6.47it/s]\u001b[A\n",
            " 44% 105/240 [00:16<00:20,  6.44it/s]\u001b[A\n",
            " 44% 106/240 [00:16<00:20,  6.44it/s]\u001b[A\n",
            " 45% 107/240 [00:16<00:20,  6.47it/s]\u001b[A\n",
            " 45% 108/240 [00:16<00:20,  6.45it/s]\u001b[A\n",
            " 45% 109/240 [00:16<00:20,  6.49it/s]\u001b[A\n",
            " 46% 110/240 [00:16<00:20,  6.45it/s]\u001b[A\n",
            " 46% 111/240 [00:17<00:19,  6.47it/s]\u001b[A\n",
            " 47% 112/240 [00:17<00:19,  6.43it/s]\u001b[A\n",
            " 47% 113/240 [00:17<00:19,  6.45it/s]\u001b[A\n",
            " 48% 114/240 [00:17<00:19,  6.43it/s]\u001b[A\n",
            " 48% 115/240 [00:17<00:19,  6.36it/s]\u001b[A\n",
            " 48% 116/240 [00:17<00:19,  6.29it/s]\u001b[A\n",
            " 49% 117/240 [00:18<00:19,  6.30it/s]\u001b[A\n",
            " 49% 118/240 [00:18<00:19,  6.31it/s]\u001b[A\n",
            " 50% 119/240 [00:18<00:19,  6.29it/s]\u001b[A\n",
            " 50% 120/240 [00:18<00:19,  6.30it/s]\u001b[A\n",
            " 50% 121/240 [00:18<00:18,  6.33it/s]\u001b[A\n",
            " 51% 122/240 [00:18<00:18,  6.37it/s]\u001b[A\n",
            " 51% 123/240 [00:19<00:18,  6.18it/s]\u001b[A\n",
            " 52% 124/240 [00:19<00:18,  6.33it/s]\u001b[A\n",
            " 52% 125/240 [00:19<00:18,  6.22it/s]\u001b[A\n",
            " 52% 126/240 [00:19<00:18,  6.27it/s]\u001b[A\n",
            " 53% 127/240 [00:19<00:17,  6.31it/s]\u001b[A\n",
            " 53% 128/240 [00:19<00:17,  6.45it/s]\u001b[A\n",
            " 54% 129/240 [00:19<00:17,  6.44it/s]\u001b[A\n",
            " 54% 130/240 [00:20<00:17,  6.34it/s]\u001b[A\n",
            " 55% 131/240 [00:20<00:16,  6.49it/s]\u001b[A\n",
            " 55% 132/240 [00:20<00:16,  6.46it/s]\u001b[A\n",
            " 55% 133/240 [00:20<00:16,  6.47it/s]\u001b[A\n",
            " 56% 134/240 [00:20<00:16,  6.48it/s]\u001b[A\n",
            " 56% 135/240 [00:20<00:16,  6.45it/s]\u001b[A\n",
            " 57% 136/240 [00:21<00:16,  6.47it/s]\u001b[A\n",
            " 57% 137/240 [00:21<00:16,  6.43it/s]\u001b[A\n",
            " 57% 138/240 [00:21<00:15,  6.47it/s]\u001b[A\n",
            " 58% 139/240 [00:21<00:15,  6.50it/s]\u001b[A\n",
            " 58% 140/240 [00:21<00:15,  6.47it/s]\u001b[A\n",
            " 59% 141/240 [00:21<00:15,  6.49it/s]\u001b[A\n",
            " 59% 142/240 [00:21<00:15,  6.49it/s]\u001b[A\n",
            " 60% 143/240 [00:22<00:14,  6.47it/s]\u001b[A\n",
            " 60% 144/240 [00:22<00:14,  6.42it/s]\u001b[A\n",
            " 60% 145/240 [00:22<00:14,  6.47it/s]\u001b[A\n",
            " 61% 146/240 [00:22<00:14,  6.41it/s]\u001b[A\n",
            " 61% 147/240 [00:22<00:14,  6.49it/s]\u001b[A\n",
            " 62% 148/240 [00:22<00:14,  6.45it/s]\u001b[A\n",
            " 62% 149/240 [00:23<00:13,  6.50it/s]\u001b[A\n",
            " 62% 150/240 [00:23<00:14,  6.33it/s]\u001b[A\n",
            " 63% 151/240 [00:23<00:13,  6.52it/s]\u001b[A\n",
            " 63% 152/240 [00:23<00:13,  6.50it/s]\u001b[A\n",
            " 64% 153/240 [00:23<00:13,  6.49it/s]\u001b[A\n",
            " 64% 154/240 [00:23<00:13,  6.43it/s]\u001b[A\n",
            " 65% 155/240 [00:23<00:13,  6.44it/s]\u001b[A\n",
            " 65% 156/240 [00:24<00:13,  6.46it/s]\u001b[A\n",
            " 65% 157/240 [00:24<00:12,  6.44it/s]\u001b[A\n",
            " 66% 158/240 [00:24<00:12,  6.46it/s]\u001b[A\n",
            " 66% 159/240 [00:24<00:12,  6.43it/s]\u001b[A\n",
            " 67% 160/240 [00:24<00:12,  6.45it/s]\u001b[A\n",
            " 67% 161/240 [00:24<00:12,  6.41it/s]\u001b[A\n",
            " 68% 162/240 [00:25<00:12,  6.47it/s]\u001b[A\n",
            " 68% 163/240 [00:25<00:11,  6.46it/s]\u001b[A\n",
            " 68% 164/240 [00:25<00:11,  6.43it/s]\u001b[A\n",
            " 69% 165/240 [00:25<00:11,  6.44it/s]\u001b[A\n",
            " 69% 166/240 [00:25<00:11,  6.43it/s]\u001b[A\n",
            " 70% 167/240 [00:25<00:11,  6.44it/s]\u001b[A\n",
            " 70% 168/240 [00:25<00:11,  6.43it/s]\u001b[A\n",
            " 70% 169/240 [00:26<00:11,  6.43it/s]\u001b[A\n",
            " 71% 170/240 [00:26<00:11,  6.34it/s]\u001b[A\n",
            " 71% 171/240 [00:26<00:10,  6.47it/s]\u001b[A\n",
            " 72% 172/240 [00:26<00:10,  6.47it/s]\u001b[A\n",
            " 72% 173/240 [00:26<00:10,  6.49it/s]\u001b[A\n",
            " 72% 174/240 [00:26<00:10,  6.46it/s]\u001b[A\n",
            " 73% 175/240 [00:27<00:10,  6.47it/s]\u001b[A\n",
            " 73% 176/240 [00:27<00:09,  6.47it/s]\u001b[A\n",
            " 74% 177/240 [00:27<00:09,  6.47it/s]\u001b[A\n",
            " 74% 178/240 [00:27<00:09,  6.47it/s]\u001b[A\n",
            " 75% 179/240 [00:27<00:09,  6.48it/s]\u001b[A\n",
            " 75% 180/240 [00:27<00:09,  6.46it/s]\u001b[A\n",
            " 75% 181/240 [00:28<00:09,  6.46it/s]\u001b[A\n",
            " 76% 182/240 [00:28<00:08,  6.47it/s]\u001b[A\n",
            " 76% 183/240 [00:28<00:08,  6.44it/s]\u001b[A\n",
            " 77% 184/240 [00:28<00:08,  6.46it/s]\u001b[A\n",
            " 77% 185/240 [00:28<00:08,  6.46it/s]\u001b[A\n",
            " 78% 186/240 [00:28<00:08,  6.45it/s]\u001b[A\n",
            " 78% 187/240 [00:28<00:08,  6.44it/s]\u001b[A\n",
            " 78% 188/240 [00:29<00:08,  6.44it/s]\u001b[A\n",
            " 79% 189/240 [00:29<00:07,  6.42it/s]\u001b[A\n",
            " 79% 190/240 [00:29<00:07,  6.37it/s]\u001b[A\n",
            " 80% 191/240 [00:29<00:07,  6.46it/s]\u001b[A\n",
            " 80% 192/240 [00:29<00:07,  6.45it/s]\u001b[A\n",
            " 80% 193/240 [00:29<00:07,  6.26it/s]\u001b[A\n",
            " 81% 194/240 [00:30<00:07,  6.37it/s]\u001b[A\n",
            " 81% 195/240 [00:30<00:07,  6.34it/s]\u001b[A\n",
            " 82% 196/240 [00:30<00:06,  6.37it/s]\u001b[A\n",
            " 82% 197/240 [00:30<00:06,  6.35it/s]\u001b[A\n",
            " 82% 198/240 [00:30<00:06,  6.34it/s]\u001b[A\n",
            " 83% 199/240 [00:30<00:06,  6.37it/s]\u001b[A\n",
            " 83% 200/240 [00:30<00:06,  6.38it/s]\u001b[A\n",
            " 84% 201/240 [00:31<00:06,  6.30it/s]\u001b[A\n",
            " 84% 202/240 [00:31<00:05,  6.35it/s]\u001b[A\n",
            " 85% 203/240 [00:31<00:05,  6.25it/s]\u001b[A\n",
            " 85% 204/240 [00:31<00:05,  6.28it/s]\u001b[A\n",
            " 85% 205/240 [00:31<00:05,  6.31it/s]\u001b[A\n",
            " 86% 206/240 [00:31<00:05,  6.43it/s]\u001b[A\n",
            " 86% 207/240 [00:32<00:05,  6.42it/s]\u001b[A\n",
            " 87% 208/240 [00:32<00:04,  6.42it/s]\u001b[A\n",
            " 87% 209/240 [00:32<00:04,  6.44it/s]\u001b[A\n",
            " 88% 210/240 [00:32<00:04,  6.27it/s]\u001b[A\n",
            " 88% 211/240 [00:32<00:04,  6.50it/s]\u001b[A\n",
            " 88% 212/240 [00:32<00:04,  6.47it/s]\u001b[A\n",
            " 89% 213/240 [00:33<00:04,  6.40it/s]\u001b[A\n",
            " 89% 214/240 [00:33<00:04,  6.44it/s]\u001b[A\n",
            " 90% 215/240 [00:33<00:03,  6.45it/s]\u001b[A\n",
            " 90% 216/240 [00:33<00:03,  6.41it/s]\u001b[A\n",
            " 90% 217/240 [00:33<00:03,  6.43it/s]\u001b[A\n",
            " 91% 218/240 [00:33<00:03,  6.46it/s]\u001b[A\n",
            " 91% 219/240 [00:33<00:03,  6.44it/s]\u001b[A\n",
            " 92% 220/240 [00:34<00:03,  6.44it/s]\u001b[A\n",
            " 92% 221/240 [00:34<00:02,  6.47it/s]\u001b[A\n",
            " 92% 222/240 [00:34<00:02,  6.43it/s]\u001b[A\n",
            " 93% 223/240 [00:34<00:02,  6.44it/s]\u001b[A\n",
            " 93% 224/240 [00:34<00:02,  6.42it/s]\u001b[A\n",
            " 94% 225/240 [00:34<00:02,  6.44it/s]\u001b[A\n",
            " 94% 226/240 [00:35<00:02,  6.43it/s]\u001b[A\n",
            " 95% 227/240 [00:35<00:02,  6.47it/s]\u001b[A\n",
            " 95% 228/240 [00:35<00:01,  6.41it/s]\u001b[A\n",
            " 95% 229/240 [00:35<00:01,  6.46it/s]\u001b[A\n",
            " 96% 230/240 [00:35<00:01,  6.34it/s]\u001b[A\n",
            " 96% 231/240 [00:35<00:01,  6.50it/s]\u001b[A\n",
            " 97% 232/240 [00:35<00:01,  6.50it/s]\u001b[A\n",
            " 97% 233/240 [00:36<00:01,  6.46it/s]\u001b[A\n",
            " 98% 234/240 [00:36<00:00,  6.44it/s]\u001b[A\n",
            " 98% 235/240 [00:36<00:00,  6.46it/s]\u001b[A\n",
            " 98% 236/240 [00:36<00:00,  6.47it/s]\u001b[A\n",
            " 99% 237/240 [00:36<00:00,  6.44it/s]\u001b[A\n",
            " 99% 238/240 [00:36<00:00,  6.45it/s]\u001b[A\n",
            "100% 239/240 [00:37<00:00,  6.44it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.47163209319114685, 'eval_runtime': 37.4044, 'eval_samples_per_second': 25.639, 'eval_steps_per_second': 6.416, 'epoch': 2.0}\n",
            " 67% 1118/1677 [13:06<04:59,  1.87it/s]\n",
            "100% 240/240 [00:37<00:00,  6.81it/s]\u001b[A\n",
            "{'loss': 0.3096, 'grad_norm': 2.3400399684906006, 'learning_rate': 8.122344944774851e-06, 'epoch': 2.15}\n",
            "{'loss': 0.282, 'grad_norm': 2.0330495834350586, 'learning_rate': 6.4231096006796944e-06, 'epoch': 2.33}\n",
            "{'loss': 0.2886, 'grad_norm': 1.7979823350906372, 'learning_rate': 4.723874256584538e-06, 'epoch': 2.5}\n",
            "{'loss': 0.308, 'grad_norm': 1.5450663566589355, 'learning_rate': 3.02463891248938e-06, 'epoch': 2.68}\n",
            "{'loss': 0.2964, 'grad_norm': 1.5045855045318604, 'learning_rate': 1.3254035683942225e-06, 'epoch': 2.86}\n",
            "100% 1677/1677 [20:09<00:00,  1.86it/s]\n",
            "  0% 0/240 [00:00<?, ?it/s]\u001b[A\n",
            "  1% 2/240 [00:00<00:18, 12.94it/s]\u001b[A\n",
            "  2% 4/240 [00:00<00:29,  8.00it/s]\u001b[A\n",
            "  2% 5/240 [00:00<00:31,  7.48it/s]\u001b[A\n",
            "  2% 6/240 [00:00<00:33,  7.09it/s]\u001b[A\n",
            "  3% 7/240 [00:00<00:33,  6.86it/s]\u001b[A\n",
            "  3% 8/240 [00:01<00:34,  6.70it/s]\u001b[A\n",
            "  4% 9/240 [00:01<00:34,  6.69it/s]\u001b[A\n",
            "  4% 10/240 [00:01<00:34,  6.61it/s]\u001b[A\n",
            "  5% 11/240 [00:01<00:34,  6.56it/s]\u001b[A\n",
            "  5% 12/240 [00:01<00:34,  6.54it/s]\u001b[A\n",
            "  5% 13/240 [00:01<00:34,  6.50it/s]\u001b[A\n",
            "  6% 14/240 [00:02<00:34,  6.50it/s]\u001b[A\n",
            "  6% 15/240 [00:02<00:34,  6.45it/s]\u001b[A\n",
            "  7% 16/240 [00:02<00:34,  6.49it/s]\u001b[A\n",
            "  7% 17/240 [00:02<00:34,  6.51it/s]\u001b[A\n",
            "  8% 18/240 [00:02<00:34,  6.49it/s]\u001b[A\n",
            "  8% 19/240 [00:02<00:34,  6.36it/s]\u001b[A\n",
            "  8% 20/240 [00:02<00:34,  6.46it/s]\u001b[A\n",
            "  9% 21/240 [00:03<00:34,  6.40it/s]\u001b[A\n",
            "  9% 22/240 [00:03<00:34,  6.32it/s]\u001b[A\n",
            " 10% 23/240 [00:03<00:34,  6.35it/s]\u001b[A\n",
            " 10% 24/240 [00:03<00:34,  6.33it/s]\u001b[A\n",
            " 10% 25/240 [00:03<00:33,  6.37it/s]\u001b[A\n",
            " 11% 26/240 [00:03<00:33,  6.37it/s]\u001b[A\n",
            " 11% 27/240 [00:04<00:33,  6.35it/s]\u001b[A\n",
            " 12% 28/240 [00:04<00:33,  6.26it/s]\u001b[A\n",
            " 12% 29/240 [00:04<00:33,  6.32it/s]\u001b[A\n",
            " 12% 30/240 [00:04<00:33,  6.27it/s]\u001b[A\n",
            " 13% 31/240 [00:04<00:33,  6.24it/s]\u001b[A\n",
            " 13% 32/240 [00:04<00:33,  6.24it/s]\u001b[A\n",
            " 14% 33/240 [00:05<00:32,  6.46it/s]\u001b[A\n",
            " 14% 34/240 [00:05<00:31,  6.47it/s]\u001b[A\n",
            " 15% 35/240 [00:05<00:31,  6.46it/s]\u001b[A\n",
            " 15% 36/240 [00:05<00:31,  6.45it/s]\u001b[A\n",
            " 15% 37/240 [00:05<00:31,  6.45it/s]\u001b[A\n",
            " 16% 38/240 [00:05<00:31,  6.45it/s]\u001b[A\n",
            " 16% 39/240 [00:05<00:31,  6.44it/s]\u001b[A\n",
            " 17% 40/240 [00:06<00:31,  6.42it/s]\u001b[A\n",
            " 17% 41/240 [00:06<00:30,  6.45it/s]\u001b[A\n",
            " 18% 42/240 [00:06<00:30,  6.41it/s]\u001b[A\n",
            " 18% 43/240 [00:06<00:30,  6.48it/s]\u001b[A\n",
            " 18% 44/240 [00:06<00:30,  6.42it/s]\u001b[A\n",
            " 19% 45/240 [00:06<00:30,  6.45it/s]\u001b[A\n",
            " 19% 46/240 [00:07<00:30,  6.45it/s]\u001b[A\n",
            " 20% 47/240 [00:07<00:29,  6.45it/s]\u001b[A\n",
            " 20% 48/240 [00:07<00:29,  6.45it/s]\u001b[A\n",
            " 20% 49/240 [00:07<00:29,  6.47it/s]\u001b[A\n",
            " 21% 50/240 [00:07<00:29,  6.46it/s]\u001b[A\n",
            " 21% 51/240 [00:07<00:29,  6.47it/s]\u001b[A\n",
            " 22% 52/240 [00:07<00:29,  6.48it/s]\u001b[A\n",
            " 22% 53/240 [00:08<00:29,  6.45it/s]\u001b[A\n",
            " 22% 54/240 [00:08<00:28,  6.45it/s]\u001b[A\n",
            " 23% 55/240 [00:08<00:28,  6.49it/s]\u001b[A\n",
            " 23% 56/240 [00:08<00:28,  6.46it/s]\u001b[A\n",
            " 24% 57/240 [00:08<00:28,  6.41it/s]\u001b[A\n",
            " 24% 58/240 [00:08<00:28,  6.48it/s]\u001b[A\n",
            " 25% 59/240 [00:09<00:27,  6.47it/s]\u001b[A\n",
            " 25% 60/240 [00:09<00:27,  6.46it/s]\u001b[A\n",
            " 25% 61/240 [00:09<00:27,  6.45it/s]\u001b[A\n",
            " 26% 62/240 [00:09<00:27,  6.45it/s]\u001b[A\n",
            " 26% 63/240 [00:09<00:27,  6.44it/s]\u001b[A\n",
            " 27% 64/240 [00:09<00:27,  6.42it/s]\u001b[A\n",
            " 27% 65/240 [00:09<00:27,  6.46it/s]\u001b[A\n",
            " 28% 66/240 [00:10<00:27,  6.44it/s]\u001b[A\n",
            " 28% 67/240 [00:10<00:26,  6.46it/s]\u001b[A\n",
            " 28% 68/240 [00:10<00:26,  6.45it/s]\u001b[A\n",
            " 29% 69/240 [00:10<00:26,  6.48it/s]\u001b[A\n",
            " 29% 70/240 [00:10<00:26,  6.44it/s]\u001b[A\n",
            " 30% 71/240 [00:10<00:26,  6.49it/s]\u001b[A\n",
            " 30% 72/240 [00:11<00:25,  6.49it/s]\u001b[A\n",
            " 30% 73/240 [00:11<00:25,  6.47it/s]\u001b[A\n",
            " 31% 74/240 [00:11<00:25,  6.46it/s]\u001b[A\n",
            " 31% 75/240 [00:11<00:25,  6.42it/s]\u001b[A\n",
            " 32% 76/240 [00:11<00:25,  6.46it/s]\u001b[A\n",
            " 32% 77/240 [00:11<00:25,  6.46it/s]\u001b[A\n",
            " 32% 78/240 [00:11<00:25,  6.44it/s]\u001b[A\n",
            " 33% 79/240 [00:12<00:25,  6.42it/s]\u001b[A\n",
            " 33% 80/240 [00:12<00:24,  6.42it/s]\u001b[A\n",
            " 34% 81/240 [00:12<00:24,  6.46it/s]\u001b[A\n",
            " 34% 82/240 [00:12<00:24,  6.44it/s]\u001b[A\n",
            " 35% 83/240 [00:12<00:24,  6.47it/s]\u001b[A\n",
            " 35% 84/240 [00:12<00:24,  6.47it/s]\u001b[A\n",
            " 35% 85/240 [00:13<00:23,  6.48it/s]\u001b[A\n",
            " 36% 86/240 [00:13<00:23,  6.47it/s]\u001b[A\n",
            " 36% 87/240 [00:13<00:23,  6.45it/s]\u001b[A\n",
            " 37% 88/240 [00:13<00:23,  6.45it/s]\u001b[A\n",
            " 37% 89/240 [00:13<00:23,  6.45it/s]\u001b[A\n",
            " 38% 90/240 [00:13<00:23,  6.43it/s]\u001b[A\n",
            " 38% 91/240 [00:13<00:23,  6.45it/s]\u001b[A\n",
            " 38% 92/240 [00:14<00:22,  6.45it/s]\u001b[A\n",
            " 39% 93/240 [00:14<00:22,  6.44it/s]\u001b[A\n",
            " 39% 94/240 [00:14<00:22,  6.43it/s]\u001b[A\n",
            " 40% 95/240 [00:14<00:22,  6.33it/s]\u001b[A\n",
            " 40% 96/240 [00:14<00:22,  6.48it/s]\u001b[A\n",
            " 40% 97/240 [00:14<00:22,  6.36it/s]\u001b[A\n",
            " 41% 98/240 [00:15<00:22,  6.42it/s]\u001b[A\n",
            " 41% 99/240 [00:15<00:22,  6.40it/s]\u001b[A\n",
            " 42% 100/240 [00:15<00:22,  6.35it/s]\u001b[A\n",
            " 42% 101/240 [00:15<00:22,  6.31it/s]\u001b[A\n",
            " 42% 102/240 [00:15<00:21,  6.35it/s]\u001b[A\n",
            " 43% 103/240 [00:15<00:21,  6.33it/s]\u001b[A\n",
            " 43% 104/240 [00:16<00:21,  6.33it/s]\u001b[A\n",
            " 44% 105/240 [00:16<00:21,  6.27it/s]\u001b[A\n",
            " 44% 106/240 [00:16<00:21,  6.24it/s]\u001b[A\n",
            " 45% 107/240 [00:16<00:21,  6.31it/s]\u001b[A\n",
            " 45% 108/240 [00:16<00:20,  6.30it/s]\u001b[A\n",
            " 45% 109/240 [00:16<00:20,  6.35it/s]\u001b[A\n",
            " 46% 110/240 [00:17<00:20,  6.24it/s]\u001b[A\n",
            " 46% 111/240 [00:17<00:20,  6.31it/s]\u001b[A\n",
            " 47% 112/240 [00:17<00:19,  6.43it/s]\u001b[A\n",
            " 47% 113/240 [00:17<00:19,  6.42it/s]\u001b[A\n",
            " 48% 114/240 [00:17<00:19,  6.43it/s]\u001b[A\n",
            " 48% 115/240 [00:17<00:19,  6.33it/s]\u001b[A\n",
            " 48% 116/240 [00:17<00:19,  6.47it/s]\u001b[A\n",
            " 49% 117/240 [00:18<00:19,  6.46it/s]\u001b[A\n",
            " 49% 118/240 [00:18<00:18,  6.47it/s]\u001b[A\n",
            " 50% 119/240 [00:18<00:18,  6.46it/s]\u001b[A\n",
            " 50% 120/240 [00:18<00:18,  6.45it/s]\u001b[A\n",
            " 50% 121/240 [00:18<00:18,  6.47it/s]\u001b[A\n",
            " 51% 122/240 [00:18<00:18,  6.46it/s]\u001b[A\n",
            " 51% 123/240 [00:19<00:18,  6.44it/s]\u001b[A\n",
            " 52% 124/240 [00:19<00:17,  6.46it/s]\u001b[A\n",
            " 52% 125/240 [00:19<00:17,  6.45it/s]\u001b[A\n",
            " 52% 126/240 [00:19<00:17,  6.45it/s]\u001b[A\n",
            " 53% 127/240 [00:19<00:17,  6.47it/s]\u001b[A\n",
            " 53% 128/240 [00:19<00:17,  6.45it/s]\u001b[A\n",
            " 54% 129/240 [00:19<00:17,  6.39it/s]\u001b[A\n",
            " 54% 130/240 [00:20<00:17,  6.41it/s]\u001b[A\n",
            " 55% 131/240 [00:20<00:16,  6.43it/s]\u001b[A\n",
            " 55% 132/240 [00:20<00:16,  6.44it/s]\u001b[A\n",
            " 55% 133/240 [00:20<00:16,  6.41it/s]\u001b[A\n",
            " 56% 134/240 [00:20<00:16,  6.46it/s]\u001b[A\n",
            " 56% 135/240 [00:20<00:16,  6.34it/s]\u001b[A\n",
            " 57% 136/240 [00:21<00:16,  6.50it/s]\u001b[A\n",
            " 57% 137/240 [00:21<00:15,  6.47it/s]\u001b[A\n",
            " 57% 138/240 [00:21<00:15,  6.47it/s]\u001b[A\n",
            " 58% 139/240 [00:21<00:15,  6.43it/s]\u001b[A\n",
            " 58% 140/240 [00:21<00:15,  6.43it/s]\u001b[A\n",
            " 59% 141/240 [00:21<00:15,  6.46it/s]\u001b[A\n",
            " 59% 142/240 [00:21<00:15,  6.47it/s]\u001b[A\n",
            " 60% 143/240 [00:22<00:15,  6.46it/s]\u001b[A\n",
            " 60% 144/240 [00:22<00:14,  6.45it/s]\u001b[A\n",
            " 60% 145/240 [00:22<00:14,  6.45it/s]\u001b[A\n",
            " 61% 146/240 [00:22<00:14,  6.45it/s]\u001b[A\n",
            " 61% 147/240 [00:22<00:14,  6.46it/s]\u001b[A\n",
            " 62% 148/240 [00:22<00:14,  6.48it/s]\u001b[A\n",
            " 62% 149/240 [00:23<00:14,  6.42it/s]\u001b[A\n",
            " 62% 150/240 [00:23<00:13,  6.46it/s]\u001b[A\n",
            " 63% 151/240 [00:23<00:13,  6.45it/s]\u001b[A\n",
            " 63% 152/240 [00:23<00:13,  6.45it/s]\u001b[A\n",
            " 64% 153/240 [00:23<00:13,  6.48it/s]\u001b[A\n",
            " 64% 154/240 [00:23<00:13,  6.45it/s]\u001b[A\n",
            " 65% 155/240 [00:23<00:13,  6.34it/s]\u001b[A\n",
            " 65% 156/240 [00:24<00:12,  6.51it/s]\u001b[A\n",
            " 65% 157/240 [00:24<00:12,  6.45it/s]\u001b[A\n",
            " 66% 158/240 [00:24<00:12,  6.49it/s]\u001b[A\n",
            " 66% 159/240 [00:24<00:12,  6.44it/s]\u001b[A\n",
            " 67% 160/240 [00:24<00:12,  6.48it/s]\u001b[A\n",
            " 67% 161/240 [00:24<00:12,  6.45it/s]\u001b[A\n",
            " 68% 162/240 [00:25<00:12,  6.46it/s]\u001b[A\n",
            " 68% 163/240 [00:25<00:11,  6.45it/s]\u001b[A\n",
            " 68% 164/240 [00:25<00:11,  6.47it/s]\u001b[A\n",
            " 69% 165/240 [00:25<00:11,  6.46it/s]\u001b[A\n",
            " 69% 166/240 [00:25<00:11,  6.47it/s]\u001b[A\n",
            " 70% 167/240 [00:25<00:11,  6.46it/s]\u001b[A\n",
            " 70% 168/240 [00:25<00:11,  6.39it/s]\u001b[A\n",
            " 70% 169/240 [00:26<00:11,  6.37it/s]\u001b[A\n",
            " 71% 170/240 [00:26<00:10,  6.37it/s]\u001b[A\n",
            " 71% 171/240 [00:26<00:10,  6.43it/s]\u001b[A\n",
            " 72% 172/240 [00:26<00:10,  6.43it/s]\u001b[A\n",
            " 72% 173/240 [00:26<00:10,  6.44it/s]\u001b[A\n",
            " 72% 174/240 [00:26<00:10,  6.46it/s]\u001b[A\n",
            " 73% 175/240 [00:27<00:10,  6.38it/s]\u001b[A\n",
            " 73% 176/240 [00:27<00:10,  6.37it/s]\u001b[A\n",
            " 74% 177/240 [00:27<00:09,  6.34it/s]\u001b[A\n",
            " 74% 178/240 [00:27<00:09,  6.40it/s]\u001b[A\n",
            " 75% 179/240 [00:27<00:09,  6.31it/s]\u001b[A\n",
            " 75% 180/240 [00:27<00:09,  6.38it/s]\u001b[A\n",
            " 75% 181/240 [00:28<00:09,  6.38it/s]\u001b[A\n",
            " 76% 182/240 [00:28<00:09,  6.32it/s]\u001b[A\n",
            " 76% 183/240 [00:28<00:09,  6.32it/s]\u001b[A\n",
            " 77% 184/240 [00:28<00:08,  6.26it/s]\u001b[A\n",
            " 77% 185/240 [00:28<00:08,  6.29it/s]\u001b[A\n",
            " 78% 186/240 [00:28<00:08,  6.21it/s]\u001b[A\n",
            " 78% 187/240 [00:28<00:08,  6.22it/s]\u001b[A\n",
            " 78% 188/240 [00:29<00:08,  6.28it/s]\u001b[A\n",
            " 79% 189/240 [00:29<00:08,  6.35it/s]\u001b[A\n",
            " 79% 190/240 [00:29<00:07,  6.44it/s]\u001b[A\n",
            " 80% 191/240 [00:29<00:07,  6.38it/s]\u001b[A\n",
            " 80% 192/240 [00:29<00:07,  6.50it/s]\u001b[A\n",
            " 80% 193/240 [00:29<00:07,  6.45it/s]\u001b[A\n",
            " 81% 194/240 [00:30<00:07,  6.46it/s]\u001b[A\n",
            " 81% 195/240 [00:30<00:07,  6.38it/s]\u001b[A\n",
            " 82% 196/240 [00:30<00:06,  6.46it/s]\u001b[A\n",
            " 82% 197/240 [00:30<00:06,  6.46it/s]\u001b[A\n",
            " 82% 198/240 [00:30<00:06,  6.47it/s]\u001b[A\n",
            " 83% 199/240 [00:30<00:06,  6.45it/s]\u001b[A\n",
            " 83% 200/240 [00:31<00:06,  6.43it/s]\u001b[A\n",
            " 84% 201/240 [00:31<00:06,  6.44it/s]\u001b[A\n",
            " 84% 202/240 [00:31<00:05,  6.39it/s]\u001b[A\n",
            " 85% 203/240 [00:31<00:05,  6.47it/s]\u001b[A\n",
            " 85% 204/240 [00:31<00:05,  6.42it/s]\u001b[A\n",
            " 85% 205/240 [00:31<00:05,  6.46it/s]\u001b[A\n",
            " 86% 206/240 [00:31<00:05,  6.45it/s]\u001b[A\n",
            " 86% 207/240 [00:32<00:05,  6.45it/s]\u001b[A\n",
            " 87% 208/240 [00:32<00:04,  6.44it/s]\u001b[A\n",
            " 87% 209/240 [00:32<00:04,  6.42it/s]\u001b[A\n",
            " 88% 210/240 [00:32<00:04,  6.48it/s]\u001b[A\n",
            " 88% 211/240 [00:32<00:04,  6.44it/s]\u001b[A\n",
            " 88% 212/240 [00:32<00:04,  6.43it/s]\u001b[A\n",
            " 89% 213/240 [00:33<00:04,  6.45it/s]\u001b[A\n",
            " 89% 214/240 [00:33<00:04,  6.43it/s]\u001b[A\n",
            " 90% 215/240 [00:33<00:03,  6.29it/s]\u001b[A\n",
            " 90% 216/240 [00:33<00:03,  6.50it/s]\u001b[A\n",
            " 90% 217/240 [00:33<00:03,  6.46it/s]\u001b[A\n",
            " 91% 218/240 [00:33<00:03,  6.47it/s]\u001b[A\n",
            " 91% 219/240 [00:33<00:03,  6.48it/s]\u001b[A\n",
            " 92% 220/240 [00:34<00:03,  6.47it/s]\u001b[A\n",
            " 92% 221/240 [00:34<00:02,  6.45it/s]\u001b[A\n",
            " 92% 222/240 [00:34<00:02,  6.42it/s]\u001b[A\n",
            " 93% 223/240 [00:34<00:02,  6.41it/s]\u001b[A\n",
            " 93% 224/240 [00:34<00:02,  6.38it/s]\u001b[A\n",
            " 94% 225/240 [00:34<00:02,  6.44it/s]\u001b[A\n",
            " 94% 226/240 [00:35<00:02,  6.44it/s]\u001b[A\n",
            " 95% 227/240 [00:35<00:02,  6.41it/s]\u001b[A\n",
            " 95% 228/240 [00:35<00:01,  6.43it/s]\u001b[A\n",
            " 95% 229/240 [00:35<00:01,  6.42it/s]\u001b[A\n",
            " 96% 230/240 [00:35<00:01,  6.41it/s]\u001b[A\n",
            " 96% 231/240 [00:35<00:01,  6.42it/s]\u001b[A\n",
            " 97% 232/240 [00:35<00:01,  6.45it/s]\u001b[A\n",
            " 97% 233/240 [00:36<00:01,  6.41it/s]\u001b[A\n",
            " 98% 234/240 [00:36<00:00,  6.45it/s]\u001b[A\n",
            " 98% 235/240 [00:36<00:00,  6.36it/s]\u001b[A\n",
            " 98% 236/240 [00:36<00:00,  6.46it/s]\u001b[A\n",
            " 99% 237/240 [00:36<00:00,  6.41it/s]\u001b[A\n",
            " 99% 238/240 [00:36<00:00,  6.47it/s]\u001b[A\n",
            "100% 239/240 [00:37<00:00,  6.47it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.48593148589134216, 'eval_runtime': 37.4272, 'eval_samples_per_second': 25.623, 'eval_steps_per_second': 6.412, 'epoch': 3.0}\n",
            "100% 1677/1677 [20:46<00:00,  1.86it/s]\n",
            "100% 240/240 [00:37<00:00,  6.80it/s]\u001b[A\n",
            "                                     \u001b[AThere were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n",
            "{'train_runtime': 1377.3865, 'train_samples_per_second': 4.868, 'train_steps_per_second': 1.218, 'train_loss': 0.7863506016876275, 'epoch': 3.0}\n",
            "100% 1677/1677 [22:57<00:00,  1.22it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "# MedSumAI Pro - Complete Implementation\n",
        "# Install required packages first: pip install transformers torch streamlit pandas accelerate datasets\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "import logging\n",
        "import warnings\n",
        "import os\n",
        "import re\n",
        "from typing import Dict, List, Any\n",
        "\n",
        "# --- Configuration ---\n",
        "FINETUNED_MODEL_PATH = \"./models/medsum-bart-finetuned\"\n",
        "BASE_MODEL = \"facebook/bart-large-cnn\"\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Check if CUDA is available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "logger.info(f\"Using device: {device}\")\n",
        "\n",
        "class LocalSummarizer:\n",
        "    def __init__(self, model_path: str):\n",
        "        \"\"\"Initialize local summarization model.\"\"\"\n",
        "        self.model_path = model_path\n",
        "        self.summarizer = None\n",
        "        self.model_name = os.path.basename(model_path) if os.path.exists(model_path) and os.listdir(model_path) else BASE_MODEL\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"Load the summarization model with memory optimization.\"\"\"\n",
        "        model_to_load = self.model_path\n",
        "\n",
        "        try:\n",
        "            # Prioritize loading the fine-tuned model if it exists\n",
        "            if os.path.exists(self.model_path) and os.listdir(self.model_path):\n",
        "                logger.info(f\"Found fine-tuned model. Loading from: {self.model_path}\")\n",
        "                # Use a session state to show toast only once\n",
        "                if 'toast_shown' not in st.session_state:\n",
        "                    st.toast(f\"ğŸš€ Using fine-tuned model: {self.model_name}\")\n",
        "                    st.session_state.toast_shown = True\n",
        "            else:\n",
        "                logger.warning(f\"Fine-tuned model not found at '{self.model_path}'. Falling back to base model.\")\n",
        "                if 'warning_shown' not in st.session_state:\n",
        "                    st.warning(f\"**Fine-tuned model not found.** Falling back to the pre-trained `{BASE_MODEL}` model. Run `train.py` to create a fine-tuned version.\")\n",
        "                    st.session_state.warning_shown = True\n",
        "                model_to_load = BASE_MODEL\n",
        "                self.model_name = BASE_MODEL\n",
        "\n",
        "            self.summarizer = pipeline(\n",
        "                \"summarization\",\n",
        "                model=model_to_load,\n",
        "                device=0 if device == \"cuda\" else -1,\n",
        "                torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
        "            )\n",
        "            logger.info(f\"âœ… Successfully loaded model: {self.model_name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Model loading failed: {e}\")\n",
        "            st.error(f\"Fatal Error: Could not load any model. Please check logs. Error: {e}\")\n",
        "            self.summarizer = None\n",
        "\n",
        "    def summarize_text(self, text: str, max_length: int = 150, min_length: int = 50) -> str:\n",
        "        \"\"\"Generate summary for given text.\"\"\"\n",
        "        if not self.summarizer:\n",
        "            return \"Model not loaded. Please check the logs for errors.\"\n",
        "\n",
        "        try:\n",
        "            text = self.clean_text(text)\n",
        "            if len(text.split()) < min_length:\n",
        "                return \"Input text is too short for a meaningful summary.\"\n",
        "\n",
        "            result = self.summarizer(\n",
        "                text,\n",
        "                max_length=max_length,\n",
        "                min_length=min_length,\n",
        "                do_sample=False,\n",
        "                truncation=True\n",
        "            )\n",
        "            return result[0]['summary_text']\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Summarization failed: {e}\")\n",
        "            return f\"Summarization failed: {str(e)}\"\n",
        "\n",
        "    def clean_text(self, text: str) -> str:\n",
        "        \"\"\"Clean and preprocess text.\"\"\"\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        text = re.sub(r'[^\\w\\s.,!?\\-]', '', text)\n",
        "        return text.strip()\n",
        "\n",
        "class PerspectiveProcessor:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize perspective detection and processing.\"\"\"\n",
        "        self.perspective_patterns = {\n",
        "            'INFORMATION': [r'\\b(definition|meaning|what is|explained|describes|causes?|symptoms?|condition|disease)\\b'],\n",
        "            'SUGGESTION': [r'\\b(should|recommend|suggest|try|consider|treatment|therapy|medication)\\b'],\n",
        "            'EXPERIENCE': [r'\\b(I have|I feel|my experience|happened to me|I noticed|I tried)\\b'],\n",
        "            'CAUSE': [r'\\b(because|due to|caused by|results from|leads to|triggers)\\b']\n",
        "        }\n",
        "\n",
        "    def extract_perspectives(self, entry: Dict) -> Dict[str, List[str]]:\n",
        "        \"\"\"Extract different perspective categories from medical Q&A entry.\"\"\"\n",
        "        perspectives = {k: [] for k in self.perspective_patterns}\n",
        "\n",
        "        all_text = f\"{entry.get('question', '')} {entry.get('context', '')} {\" \".join(entry.get('answers', []))}\"\n",
        "        sentences = re.split(r'[.!?]+', all_text.lower())\n",
        "\n",
        "        for sentence in sentences:\n",
        "            if len(sentence.strip()) > 10:\n",
        "                for perspective, patterns in self.perspective_patterns.items():\n",
        "                    if any(re.search(p, sentence, re.IGNORECASE) for p in patterns):\n",
        "                        perspectives[perspective].append(sentence.strip())\n",
        "                        break\n",
        "        return perspectives\n",
        "\n",
        "class DualAudienceGenerator:\n",
        "    def __init__(self, summarizer: LocalSummarizer, perspective_processor: PerspectiveProcessor):\n",
        "        \"\"\"Initialize dual-audience summary generator.\"\"\"\n",
        "        self.summarizer = summarizer\n",
        "        self.perspective_processor = perspective_processor\n",
        "        self.patient_templates = {\n",
        "            'INFORMATION': \"Here's what you should know: {}\",\n",
        "            'SUGGESTION': \"Your healthcare team suggests: {}\",\n",
        "            'EXPERIENCE': \"Other patients have shared: {}\",\n",
        "            'CAUSE': \"This happens because: {}\"\n",
        "        }\n",
        "        self.clinician_templates = {\n",
        "            'INFORMATION': \"Clinical Information: {}\",\n",
        "            'SUGGESTION': \"Treatment Protocol: {}\",\n",
        "            'EXPERIENCE': \"Patient-Reported Outcomes: {}\",\n",
        "            'CAUSE': \"Etiology & Pathophysiology: {}\"\n",
        "        }\n",
        "\n",
        "    def _generate_summary_for_audience(self, entry: Dict, audience: str) -> str:\n",
        "        \"\"\"Generic summary generation logic for either audience.\"\"\"\n",
        "        templates = self.patient_templates if audience == 'patient' else self.clinician_templates\n",
        "        max_len, min_len = (80, 20) if audience == 'patient' else (120, 30)\n",
        "\n",
        "        try:\n",
        "            perspectives = self.perspective_processor.extract_perspectives(entry)\n",
        "            sections = []\n",
        "\n",
        "            for perspective, segments in perspectives.items():\n",
        "                if segments:\n",
        "                    combined_text = \". \".join(segments[:3] if audience == 'patient' else segments)\n",
        "                    summary = self.summarizer.summarize_text(combined_text, max_length=max_len, min_length=min_len)\n",
        "                    sections.append(templates.get(perspective, \"{}\").format(summary))\n",
        "\n",
        "            if not sections:\n",
        "                return self._generate_fallback_summary(entry, audience)\n",
        "\n",
        "            full_summary = \"\\n\\n\".join(sections)\n",
        "            disclaimer = self._get_disclaimer(audience, entry)\n",
        "            return full_summary + disclaimer\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"{audience.capitalize()} summary generation failed: {e}\")\n",
        "            return self._generate_fallback_summary(entry, audience)\n",
        "\n",
        "    def generate_patient_summary(self, entry: Dict) -> str:\n",
        "        return self._generate_summary_for_audience(entry, 'patient')\n",
        "\n",
        "    def generate_clinician_summary(self, entry: Dict) -> str:\n",
        "        return self._generate_summary_for_audience(entry, 'clinician')\n",
        "\n",
        "    def _get_disclaimer(self, audience: str, entry: Dict) -> str:\n",
        "        if audience == 'patient':\n",
        "            return (\n",
        "                    \"\\n\\nâš ï¸ **Important**: This summary is for informational purposes only. \"\n",
        "                    \"Always consult with your healthcare provider.\")\n",
        "        else: # Clinician\n",
        "            metadata = [f\"Source: {entry.get('uri', 'N/A')}\", f\"Response Count: {len(entry.get('answers', []))}\"]\n",
        "            return (\n",
        "                    f\"\\n\\nğŸ“‹ **Metadata**: { ' | '.join(metadata)}\\n\\n\"\n",
        "                    \"ğŸ”¬ **Note**: AI-generated summary for clinical reference. Verify information independently.\")\n",
        "\n",
        "    def _generate_fallback_summary(self, entry: Dict, audience: str) -> str:\n",
        "        \"\"\"Fallback summary when perspective processing fails.\"\"\"\n",
        "        logger.warning(f\"Generating fallback summary for {audience}.\")\n",
        "        text_to_summarize = f\"Question: {entry.get('question', '')} Answers: {\" \".join(entry.get('answers', []))}\"\n",
        "        max_len = 100 if audience == 'patient' else 120\n",
        "        summary = self.summarizer.summarize_text(text_to_summarize, max_length=max_len)\n",
        "        return summary + self._get_disclaimer(audience, entry)\n",
        "\n",
        "@st.cache_resource\n",
        "def get_summarizer() -> LocalSummarizer:\n",
        "    \"\"\"Initializes and loads the summarizer model, caching it.\"\"\"\n",
        "    logger.info(\"Initializing MedSumAI Pro...\")\n",
        "    summarizer = LocalSummarizer(model_path=FINETUNED_MODEL_PATH)\n",
        "    summarizer.load_model()\n",
        "    logger.info(\"MedSumAI Pro initialization complete!\")\n",
        "    return summarizer\n",
        "\n",
        "def create_streamlit_app():\n",
        "    \"\"\"Create the Streamlit web interface.\"\"\"\n",
        "    st.set_page_config(page_title=\"MedSumAI Pro\", page_icon=\"ğŸ¥\", layout=\"wide\")\n",
        "\n",
        "    # Load model and processors\n",
        "    summarizer = get_summarizer()\n",
        "    if not summarizer or not summarizer.summarizer:\n",
        "        st.error(\"Model could not be loaded. The application cannot proceed.\")\n",
        "        return\n",
        "\n",
        "    perspective_processor = PerspectiveProcessor()\n",
        "    audience_generator = DualAudienceGenerator(summarizer, perspective_processor)\n",
        "\n",
        "    st.title(\"ğŸ¥ MedSumAI Pro - Medical Q&A Summarizer\")\n",
        "    st.markdown(\"*Perspective-aware medical summarization for patients and clinicians*\")\n",
        "\n",
        "    st.sidebar.header(\"âš™ï¸ Options\")\n",
        "    processing_mode = st.sidebar.selectbox(\"Processing Mode\", [\"Quick Summary\", \"Detailed Analysis\"], help=\"Quick mode is faster, Detailed is more comprehensive.\")\n",
        "\n",
        "    col1, col2 = st.columns([1, 1])\n",
        "    with col1:\n",
        "        st.header(\"ğŸ“ Input\")\n",
        "        input_text = st.text_area(\"Paste Medical Q&A Content:\", height=200, placeholder=\"Enter medical question and answers here...\")\n",
        "        st.markdown(\"**Or upload a JSON file:**\")\n",
        "        uploaded_file = st.file_uploader(\"Choose JSON file\", type=['json'])\n",
        "        process_button = st.button(\"ğŸ”„ Generate Summaries\", type=\"primary\")\n",
        "\n",
        "    with col2:\n",
        "        st.header(\"ğŸ“Š Output\")\n",
        "        if process_button:\n",
        "            if not input_text and not uploaded_file:\n",
        "                st.error(\"Please provide text input or upload a JSON file.\")\n",
        "                return\n",
        "\n",
        "            with st.spinner(\"Processing medical content...\"):\n",
        "                entry = {}\n",
        "                if uploaded_file:\n",
        "                    try:\n",
        "                        file_content = json.load(uploaded_file)\n",
        "                        entry = file_content[0] if isinstance(file_content, list) else file_content\n",
        "                    except json.JSONDecodeError:\n",
        "                        st.error(\"Invalid JSON file. Please check the file format.\")\n",
        "                        return\n",
        "                else:\n",
        "                    # Simple parsing for text input\n",
        "                    lines = input_text.splitlines()\n",
        "                    entry = {\n",
        "                        'question': lines[0] if lines else \"\",\n",
        "                        'answers': lines[1:] if len(lines) > 1 else [],\n",
        "                        'uri': 'user-input'\n",
        "                    }\n",
        "\n",
        "                patient_summary = audience_generator.generate_patient_summary(entry)\n",
        "                clinician_summary = audience_generator.generate_clinician_summary(entry)\n",
        "\n",
        "            tab1, tab2, tab3 = st.tabs([\"ğŸ‘¤ Patient View\", \"ğŸ©º Clinician View\", \"ğŸ“‹ Details\"])\n",
        "            with tab1:\n",
        "                st.markdown(patient_summary)\n",
        "                st.download_button(\"ğŸ“¥ Download Patient Summary\", patient_summary, \"patient_summary.txt\")\n",
        "            with tab2:\n",
        "                st.markdown(clinician_summary)\n",
        "                st.download_button(\"ğŸ“¥ Download Clinical Summary\", clinician_summary, \"clinical_summary.txt\")\n",
        "            with tab3:\n",
        "                st.metric(\"Model Used\", summarizer.model_name)\n",
        "                with st.expander(\"Raw Input Data\"):\n",
        "                    st.json(entry)\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"*MedSumAI Pro v1.0 - AI-powered medical summarization for educational purposes.*\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    create_streamlit_app()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mtzDT89LD3J",
        "outputId": "29a7faa2-16f4-4ec3-9286-a227a4fb722e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jLWXJio3uMv",
        "outputId": "5b6426f3-0338-4170-d324-cccca21f2594"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0Kâ ™\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.82.59.38:8501\u001b[0m\n",
            "\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}